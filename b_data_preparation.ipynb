{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import Transformer\n",
    "\n",
    "from src.SpacyTransformer import SpacyTransformer\n",
    "from src.AuthorLabelTransformer import AuthorLabeler\n",
    "from src.TitleLabelTransformer import TitleLabeler\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, Word2Vec, NGram\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data.json into Spark SQL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = 'data/data.json'\n",
    "df = spark.read.json(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "None\n",
      "9050\n",
      "+----------+--------------------+-----------------+\n",
      "|    author|             excerpt|            title|\n",
      "+----------+--------------------+-----------------+\n",
      "|JaneAusten|Chapter 1 || It i...|PrideAndPrejudice|\n",
      "|JaneAusten|“What is his name...|PrideAndPrejudice|\n",
      "|JaneAusten|“In such cases, a...|PrideAndPrejudice|\n",
      "+----------+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.printSchema())\n",
    "print(df.count())\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[author: string, excerpt: string, title: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create debugging data\n",
    "df5 = df.sample(withReplacement=False, fraction=0.02, seed=42)\n",
    "df5.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up transformers\n",
    "author_labeler = AuthorLabeler(inputCol='author', outputCol='author_label')\n",
    "title_labeler = TitleLabeler(inputCol='title', outputCol='title_label')\n",
    "tokenizer = SpacyTransformer(inputCol='excerpt', outputCol='words')\n",
    "countvec = CountVectorizer(inputCol=tokenizer.getOutputCol(), outputCol='termfreq')\n",
    "idf = IDF(inputCol=countvec.getOutputCol(), outputCol='tfidf')\n",
    "w2v_2d = Word2Vec(vectorSize=2, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_2d')\n",
    "w2v_large = Word2Vec(vectorSize=250, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 52 ms, total: 276 ms\n",
      "Wall time: 40min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build pipeline and run pipeline\n",
    "pipeline = Pipeline(stages=[author_labeler, title_labeler,\n",
    "                            tokenizer, countvec, \n",
    "                            idf, w2v_2d, w2v_large])\n",
    "data = pipeline.fit(df).transform(df)\n",
    "data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- termfreq: vector (nullable = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 57.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create new data frame without extraneous columns\n",
    "data2 = data.select(['words', 'tfidf', 'w2v_2d', 'w2v_large', \n",
    "                      'author_label', 'title_label'])\n",
    "\n",
    "data2.persist()\n",
    "print(data.printSchema())\n",
    "print(data2.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 32 ms, total: 148 ms\n",
      "Wall time: 31min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save data frame\n",
    "data2.write.mode('overwrite').save('data/processed_data.parquet', format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_aut_tfidf = data.select(['tfidf', 'author_label'])\n",
    "data_aut_tfidf.write.mode('overwrite').save('data/data_aut_tfidf.parquet', format='parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
