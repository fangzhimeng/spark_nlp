{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, NumericType, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import Transformer\n",
    "\n",
    "from spacy.en import English\n",
    "\n",
    "from src.SpacyTransformer import SpacyTransformer\n",
    "from src.LabelTransformer import LabelTransformer\n",
    "from src.label_udfs import author_labels, title_labels \n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, Word2Vec, NGram\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data.json into Spark SQL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = 'data/data.json'\n",
    "df = spark.read.json(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "None\n",
      "9050\n",
      "+----------+--------------------+-----------------+\n",
      "|    author|             excerpt|            title|\n",
      "+----------+--------------------+-----------------+\n",
      "|JaneAusten|Chapter 1 || It i...|PrideAndPrejudice|\n",
      "|JaneAusten|“What is his name...|PrideAndPrejudice|\n",
      "|JaneAusten|“In such cases, a...|PrideAndPrejudice|\n",
      "+----------+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.printSchema())\n",
    "print(df.count())\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[author: string, excerpt: string, title: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create debugging data\n",
    "df5 = df.sample(withReplacement=False, fraction=0.02, seed=42)\n",
    "df5.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up transformers\n",
    "tokenizer = SpacyTransformer(inputCol='excerpt', outputCol='words')\n",
    "countvec = CountVectorizer(inputCol=tokenizer.getOutputCol(), outputCol='termfreq')\n",
    "idf = IDF(inputCol=countvec.getOutputCol(), outputCol='tfidf')\n",
    "w2v_2d = Word2Vec(vectorSize=2, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_2d')\n",
    "w2v_large = Word2Vec(vectorSize=250, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 204 ms, sys: 32 ms, total: 236 ms\n",
      "Wall time: 40min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build pipeline and run pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, countvec, idf, w2v_2d, w2v_large])\n",
    "data = pipeline.fit(df).transform(df)\n",
    "data.persist()\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create int labels for author and title\n",
    "udf_author_labels = udf(author_labels, IntegerType())\n",
    "udf_title_labels = udf(title_labels, IntegerType())\n",
    "\n",
    "data2 = data.withColumn('author_label', udf_author_labels('author'))\n",
    "data3 = data2.withColumn('title_label', udf_title_labels('title'))\n",
    "\n",
    "data2.persist()\n",
    "data3.persist()\n",
    "data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- termfreq: vector (nullable = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 39.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create new data frame without extraneous columns\n",
    "data4 = data3.select(['words', 'tfidf', 'w2v_2d', 'w2v_large', \n",
    "                      'author_label', 'title_label'])\n",
    "\n",
    "print(data3.printSchema())\n",
    "print(data4.printSchema())\n",
    "\n",
    "data4.persist()\n",
    "data2.unpersist()\n",
    "data3.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 24 ms, total: 148 ms\n",
      "Wall time: 32min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save data frame\n",
    "data4.write.mode('overwrite').save('data/processed_data.parquet', format='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Make train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splits = data4.randomSplit(weights=[0.75, 0.25], seed=42)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "train.persist()\n",
    "test.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier for author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb1 = NaiveBayes(smoothing=1.0, \n",
    "                 modelType='multinomial',\n",
    "                 labelCol='author_label',\n",
    "                 featuresCol='tfidf')\n",
    "model1 = nb1.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions1 = model1.transform(test)\n",
    "predictions1.persist()\n",
    "print(predictions1.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol='author_label',\n",
    "                                               predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author test set accuracy = 0.9920443502350802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[words: array<string>, tfidf: vector, w2v_2d: vector, w2v_large: vector, author_label: int, title_label: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1 = evaluator1.evaluate(predictions1)\n",
    "print('Author test set accuracy = ' + str(accuracy1))\n",
    "predictions1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 767 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb2 = NaiveBayes(smoothing=1.0, \n",
    "                 modelType='multinomial',\n",
    "                 labelCol='title_label',\n",
    "                 featuresCol='tfidf')\n",
    "model2 = nb2.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 66.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = model2.transform(test)\n",
    "predictions2.persist()\n",
    "print(predictions2.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol='title_label',\n",
    "                                               predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title test set accuracy = 0.07133608564630645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[words: array<string>, tfidf: vector, w2v_2d: vector, w2v_large: vector, author_label: int, title_label: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2 = evaluator2.evaluate(predictions2)\n",
    "print('Title test set accuracy = ' + str(accuracy2))\n",
    "\n",
    "data4.unpersist()\n",
    "predictions2.unpersist()\n",
    "train.unpersist()\n",
    "test.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
