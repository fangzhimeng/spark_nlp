{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, NumericType, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import Transformer\n",
    "\n",
    "from spacy.en import English\n",
    "\n",
    "from src.SpacyTransformer import SpacyTransformer\n",
    "from src.LabelTransformer import LabelTransformer\n",
    "from src.label_udfs import author_labels, title_labels \n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, Word2Vec, NGram\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data.json into Spark SQL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = 'data/data.json'\n",
    "df = spark.read.json(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "None\n",
      "9050\n",
      "+----------+--------------------+-----------------+\n",
      "|    author|             excerpt|            title|\n",
      "+----------+--------------------+-----------------+\n",
      "|JaneAusten|Chapter 1 || It i...|PrideAndPrejudice|\n",
      "|JaneAusten|“What is his name...|PrideAndPrejudice|\n",
      "|JaneAusten|“In such cases, a...|PrideAndPrejudice|\n",
      "+----------+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.printSchema())\n",
    "print(df.count())\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[author: string, excerpt: string, title: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create debugging data\n",
    "df5 = df.sample(withReplacement=False, fraction=0.02, seed=42)\n",
    "df5.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up transformers\n",
    "tokenizer = SpacyTransformer(inputCol='excerpt', outputCol='words')\n",
    "countvec = CountVectorizer(inputCol=tokenizer.getOutputCol(), outputCol='termfreq')\n",
    "idf = IDF(inputCol=countvec.getOutputCol(), outputCol='tfidf')\n",
    "w2v_2d = Word2Vec(vectorSize=2, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_2d')\n",
    "w2v_large = Word2Vec(vectorSize=250, minCount=2, inputCol=tokenizer.getOutputCol(), outputCol='w2v_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    author|             excerpt|            title|               words|            termfreq|               tfidf|              w2v_2d|           w2v_large|\n",
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|JaneAusten|Chapter 1 || It i...|PrideAndPrejudice|[Chapter, 1, ||, ...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1537176836475...|[-0.0043571270131...|\n",
      "|JaneAusten|“What is his name...|PrideAndPrejudice|[“, What, is, his...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1880662840808...|[0.00572840133550...|\n",
      "|JaneAusten|“In such cases, a...|PrideAndPrejudice|[“, In, such, cas...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1603233745282...|[0.01362464603545...|\n",
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 332 ms, sys: 52 ms, total: 384 ms\n",
      "Wall time: 1h 13min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build pipeline and run pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, countvec, idf, w2v_2d, w2v_large])\n",
    "data = pipeline.fit(df).transform(df)\n",
    "data.persist()\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+\n",
      "|    author|             excerpt|            title|               words|            termfreq|               tfidf|              w2v_2d|           w2v_large|author_label|title_label|\n",
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+\n",
      "|JaneAusten|Chapter 1 || It i...|PrideAndPrejudice|[Chapter, 1, ||, ...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1537176836475...|[-0.0043571270131...|           0|          4|\n",
      "|JaneAusten|“What is his name...|PrideAndPrejudice|[“, What, is, his...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1880662840808...|[0.00572840133550...|           0|          4|\n",
      "|JaneAusten|“In such cases, a...|PrideAndPrejudice|[“, In, such, cas...|(50727,[0,1,2,3,4...|(50727,[0,1,2,3,4...|[-0.1603233745282...|[0.01362464603545...|           0|          4|\n",
      "+----------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 152 ms, sys: 20 ms, total: 172 ms\n",
      "Wall time: 32min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create int labels for author and title\n",
    "udf_author_labels = udf(author_labels, IntegerType())\n",
    "udf_title_labels = udf(title_labels, IntegerType())\n",
    "\n",
    "data2 = data.withColumn('author_label', udf_author_labels('author'))\n",
    "data3 = data2.withColumn('title_label', udf_title_labels('title'))\n",
    "\n",
    "data3.persist()\n",
    "data.unpersist()\n",
    "data3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- excerpt: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- termfreq: vector (nullable = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tfidf: vector (nullable = true)\n",
      " |-- w2v_2d: vector (nullable = true)\n",
      " |-- w2v_large: vector (nullable = true)\n",
      " |-- author_label: integer (nullable = true)\n",
      " |-- title_label: integer (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 59.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create new data frame without extraneous columns\n",
    "data4 = data3.select(['words', 'tfidf', 'w2v_2d', 'w2v_large', \n",
    "                      'author_label', 'title_label'])\n",
    "\n",
    "print(data3.printSchema())\n",
    "print(data4.printSchema())\n",
    "\n",
    "data4.persist()\n",
    "data3.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 16 ms, total: 152 ms\n",
      "Wall time: 32min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save data frame\n",
    "data4.write.mode('overwrite').save('data/processed_data.parquet', format='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Make train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splits = data4.randomSplit(weights=[0.75, 0.25], seed=42)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "train.persist()\n",
    "test.persist()\n",
    "data4.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier for author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 28 ms, total: 152 ms\n",
      "Wall time: 32min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb1 = NaiveBayes(smoothing=1.0, \n",
    "                 modelType='multinomial',\n",
    "                 labelCol='author_label',\n",
    "                 featuresCol='tfidf')\n",
    "model1 = nb1.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|               words|               tfidf|              w2v_2d|           w2v_large|author_label|title_label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|[ , ||, Appendix,...|(50727,[0,1,3,4,5...|[-0.0391773918012...|[-0.0073203907892...|           2|         15|[-13587.688600909...|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[ , ||, CHAPTER, ...|(50727,[0,1,2,3,4...|[-0.1021926742108...|[0.00169267584128...|           1|          7|[-6328.0520035366...|[1.93642110382305...|       1.0|\n",
      "|[ , ||, CHAPTER, ...|(50727,[0,1,2,3,4...|[-0.1324708268134...|[0.03663685781380...|           0|          5|[-5214.6952657203...|   [1.0,0.0,0.0,0.0]|       0.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 104 ms, sys: 44 ms, total: 148 ms\n",
      "Wall time: 32min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions1 = model1.transform(test)\n",
    "predictions1.persist()\n",
    "predictions1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol='author_label',\n",
    "                                               predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author test set accuracy = 0.9920443502350802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[words: array<string>, tfidf: vector, w2v_2d: vector, w2v_large: vector, author_label: int, title_label: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1 = evaluator1.evaluate(predictions1)\n",
    "print('Author test set accuracy = ' + str(accuracy1))\n",
    "predictions1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 697 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb2 = NaiveBayes(smoothing=1.0, \n",
    "                 modelType='multinomial',\n",
    "                 labelCol='title_label',\n",
    "                 featuresCol='tfidf')\n",
    "model2 = nb2.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|               words|               tfidf|              w2v_2d|           w2v_large|author_label|title_label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|[ , ||, Appendix,...|(50727,[0,1,3,4,5...|[-0.0391773918012...|[-0.0073203907892...|           2|         15|[-12646.429028809...|[0.0,0.0,0.0,0.0,...|      14.0|\n",
      "|[ , ||, CHAPTER, ...|(50727,[0,1,2,3,4...|[-0.1021926742108...|[0.00169267584128...|           1|          7|[-6257.4194521038...|[5.19451039268454...|       8.0|\n",
      "|[ , ||, CHAPTER, ...|(50727,[0,1,2,3,4...|[-0.1324708268134...|[0.03663685781380...|           0|          5|[-5571.2612098319...|[5.66222742076090...|       4.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = model2.transform(test)\n",
    "predictions2.persist()\n",
    "predictions2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 6.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol='title_label',\n",
    "                                               predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title test set accuracy = 0.07133608564630645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[words: array<string>, tfidf: vector, w2v_2d: vector, w2v_large: vector, author_label: int, title_label: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2 = evaluator2.evaluate(predictions2)\n",
    "print('Title test set accuracy = ' + str(accuracy2))\n",
    "\n",
    "predictions2.unpersist()\n",
    "train.unpersist()\n",
    "test.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
